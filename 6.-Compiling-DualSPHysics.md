- [6.1 Pre-requisites: Software needed before you compile](#61-pre-requisites)
- [6.2 Location of the source code](#62-location-of-the-source-code)
- [6.3 Structure of the code](#63-structure-of-the-code)
- [COMMON FILES:](#common-files-)
- [COMMON_BINARYFILES:](#common-binaryfiles-)
- [COMMON_LIBJFORMATFILES2:](#common-libjformatfiles2-)
- [COMMON_LIBJWAVEGEN:](#common-libjwavegen-)
- [COMMON_MOTION:](#common-motion-)
- [SPH SOLVER:](#sph-solver-)
- [SPH SOLVER ONLY FOR CPU EXECUTIONS:](#sph-solver-only-for-cpu-executions-)
- [SPH SOLVER ONLY FOR GPU EXECUTIONS:](#sph-solver-only-for-gpu-executions-)
- [CPU Source files](#cpu-source-files)
- [GPU source files](#gpu-source-files)
- [6.4 Compiling on Windows using VS](#64-compiling-on-windows-using-vs)
- [6.5 Compiling on Linux](#65-compiling-on-linux)
- [6.6 Compiling using CMAKE](#66-compiling-using-cmake)

<small><i><a href='http://ecotrust-canada.github.io/markdown-toc/'>Table of contents generated with markdown-toc</a></i></small>
## 6.1 Pre-requisites: Software needed before you compile

The code can be compiled for either CPU or CPU&GPU. 
You need to install the C++ compiler (for example gcc) and the CUDA compiler (nvcc).
Please note that both the C++ and CUDA version of the code contain the same features and options. Most of the source code is common to CPU and GPU, which allows the code to be run on workstations without a CUDA-enabled GPU, using only the CPU implementation.

To run DualSPHysics on a GPU using an executable, only an Nvidia CUDA-enabled GPU card is needed and the latest version of the GPU driver must be installed. However, to compile the source code, the GPU programming language CUDA and nvcc compiler must be installed on your computer. CUDA Toolkit X.X can be downloaded from Nvidia website [http://developer.nvidia.com/cuda-toolkit-XX](http://developer.nvidia.com/cuda-toolkit-XX). CUDA versions from 4.0 till 9.2 have been tested.


## 6.2 Location of the source code

The user can download the whole package from http://dual.sphysics.org/index.php/downloads/
The folder **src/source** contains the source files of v5.0 (.cpp, .cu and .h). 
The makefile of linux and the text file for CMAKE.txt are also included in this folder.
Visual studio (Community 2015) project for windows can be found in **src/VS**.
The libraries (.a and .lib) necessary for compilation are included in **src/lib**.

In addition the source code is also in the [GitHub repository](https://github.com/DualSPHysics/DualSPHysics). 
You can learn Git and GitHub using the [Hello World guide](https://guides.github.com/activities/hello-world/), which explains how to start a branch, write comments, and open a pull request.


## 6.3 Structure of the code

A complete list of these source files is summarised in Table 6-1. Some files are shared with other codes such as GenCase, BoundaryVTK, PartVTK, PartVTKOut, MeasureTool and IsoSurface. The rest of the files implement the SPH solver, some of them are used both for CPU/GPU executions and others are specific.

<p align="center">
<strong>Table 6-1.</strong> List of source files of DualSPHysics v4.2 code.
</p>
<p align="center">
<img src="https://i.imgur.com/sLCH6VJ.png"/>
</p>
<p align="center">
<img src="https://i.imgur.com/bSPABnU.png"/>
</p>


## 6.3.1 COMMON FILES:

### Functions.h & Functions.cpp
Declares/implements basic/general functions for the entire application.

### FunctionsMath.h & FunctionsMath.cpp
Declares/implements basic/general math functions.

### JDsphConfig.h & JDsphConfig.cpp
Declares/implements the class that loads configuration from DphConfig.xml.

### JException.h & JException.cpp
Declares/implements the class that defines exceptions with the information of the class and method.

### JLog2.h & JLog2.cpp
Declares/implements the class that manages the output of information in the file Run.out and on screen.

### JMatrix4.h 
Declares the template for a matrix 4x4 used for geometric transformation of points in space.

### JMeanValues.h & JMeanValues.cpp
Declares/implements the class that calculates the average value of a sequence of values.

### JObject.h & JObject.cpp
Declares/implements the class that defines objects with methods that throw exceptions.

### JParticlesDef.h 
Defines type of particles and basic methods for particles.

### JPeriodicDef.h
Defines type of periodic conditions and basic functionalities.

### JRadixSort.h & JRadixSort.cpp
Declares/implements the class that implements the algorithm RadixSort.

### JRangeFilter.h & JRangeFilter.cpp
Declares/implements the class that facilitates filtering values within a list.

### JReadDatafile.h & JReadDatafile.cpp
Declares/implements the class that allows reading data in ASCII files. 

### JSaveCsv2.h & JSaveCsv2.cpp
Declares/implements the class that create CSV files. 

### JSpaceCtes.h & JSpaceCtes.cpp
Declares/implements the class that manages the info of constants from the input XML file.

### JSpaceEParms.h & JSpaceEParms.cpp
Declares/implements the class that manages the info of execution parameters from the input XML file.

### JSpaceParts.h & JSpaceParts.cpp
Declares/implements the class that manages the info of particles from the input XML file.

### JSpaceProperties.h & JSpaceProperties.cpp
Declares/implements the class that manages the properties assigned to the particles in the XML file.

### JTimeControl.h & JTimeControl.cpp
Declares/implements the class that manages the information of runtime in long processes.

### JTimer.h 
Declares the class that defines a class to measure short time intervals.

### JTimerClock.h 
Declares the class to measure time intervals with precision of clock().

### JXml.h & JXml.cpp
Declares the class that helps to manage the XML document using library TinyXML.

### TypesDef.h
Declares general types and functions for the entire application.

## COMMON_BINARYFILES:

### JBinaryData.h & JBinaryData.cpp
Declares/implements the class that defines any binary format of a file. 

### JPartDataBi4.h & JPartDataBi4.cpp
Declares/implements the class that allows reading files with data of particles in format bi4.

### JPartDataHead.h & JPartDataHead.cpp
Declares/implements the class that manages the information of simulation data.

### JPartFloatBi4.h & JPartFloatBi4.cpp
Declares/implements the class that allows reading information of floating objects saved during simulation.

### JPartOutBi4Save.h & JPartOutBi4Save.cpp
Declares/implements the class that allows writing information of excluded particles during simulation.

### COMMON_GPU:

### FunctionsCuda.h & FunctionsCuda.cpp
Declares/implements basic/general GPU functions for the entire application.

### FunctionsMath_ker.cu
Declares/implements basic/general math functions for the GPU execution.

### JObjectGpu.h & JObjectGpu.cpp
Declares/implements the class that defines objects with methods that throw exceptions for tasks on the GPU.

### JReduSum_ker.h &  JReduSum_ker.cu
Declares/implements the class that defines objects with methods that throw exceptions for tasks on the GPU.

### JTimerCuda.h 
Declares the class that defines a class to measure short time intervals on the GPU using cudaEvent.

## COMMON_LIBJFORMATFILES2:

### JFormatFiles2.h
Declares the class that provides functions to store particle data in formats VTK, CSV, ASCII and geometric elements in VTK format

### JFormatFiles2_x64.lib (libjformatfiles2_64.a)
Precompiled library that provides functions to store particle data in formats VTK, CSV, ASCII and geometric elements in VTK format

## COMMON_LIBJWAVEGEN:

### JWaveGen.h
Declares the class that implements wave generation for regular and irregular waves.

### JWaveOrder2_ker.h & JWaveOrder2_ker.cu
Declares/implements functions and CUDA kernels for second order irregular wave generation.

### JWaveSpectrumGpu.h & JWaveSpectrumGpu.cpp
Declares/implements the class that manages the GPU computations for irregular wave generation.

### JWaveGen_x64.lib (libjwavegen_64.a)
Precompiled library that implements wave generation for regular and irregular waves.

## COMMON_MOTION:

### JMotion.h & JMotion.CPP
Declares/ implements the class that provides the displacement of moving objects during a time interval.

### JMotionEvent.h
Declares the class that manages events for motions.  

### JMotionList.h & JMotionList.cpp
Declares/implements the classes that manages the state and the list of different motions.

### JMotionMov.h & JMotionMov.cpp
Declares/implements the class that defines data for each motion type.

### JMotionObj.h & JMotionObj.cpp
Declares/implements the classes that manages the active motions and the hierarchy of motions.

### JMotionPos.h & JMotionPos.cpp
Declares/implements the class that manages the position of objects.

## 6.3.2 SPH SOLVER:

### main.cpp
Main file of the project that executes the code on CPU or GPU.

### JCfgRun.h & JCfgRun.cpp
Declares/implements the class that defines the class responsible for collecting the execution parameters by command line.

### JDamping.h & JDamping.cpp
Declares/implements the class that manages the info of damping zones. 

### JGaugeItem.h & JGaugeItem.cpp
Declares/implements the class that defines the common part of different gauge types.

### JGaugeSystem.h & JGaugeSystem.cpp
Declares/implements the class that manages the list of configured gauge.

### JPartsLoad4.h & JPartsLoad4.cpp
Declares/implements the class that manages the initial load of particle data.

### JPartsOut.h & JPartsOut.cpp
Declares/implements the class that stores excluded particles at each instant until writing the output file.

### JSaveDt.h & JSaveDt.cpp
Declares/implements the class that manages the use of prefixed values of DT loaded from an input file.

### JSph.h & JSph.cpp
Declares/implements the class that defines all the attributes and functions CPU & GPU simulations share.

### JSphAccInput.h & JSphAccInput .cpp
Declares/implements the class that manages the external forces applied to different blocks of particles.

### JSphDtFixed.h & JSphDtFixed.cpp
Declares/implements the class that manages the info of dt.

### JSphInitialize.h & JSphInitialize.cpp
Declares/implements the class that manages the info of particles from the input XML file.

### JSphMk.h & JSphMk.cpp
Declares/implements the class that manages the info of particles according Mk.

### JSphMotion.h & JSphMotion.cpp
Declares/implements the class that provides the displacement for moving particles during a time interval.

### JSphVisco.h & JSphVisco.cpp
Declares/implements the class that manages the use of viscosity values from an input file.

### JTimeOut.h & JTimeOut.cpp
Declares/implements the class that manages the use of variable output time to save PARTs.

### OmpDefs.h 
Defines constants to use of OpenMP.

### Types.h 
Defines specific types for the SPH application.

## SPH SOLVER ONLY FOR CPU EXECUTIONS

### JArraysCpu.h & JArraysCpu.cpp
Declares/implements the class that manages arrays with memory allocated in CPU.

### JCellDivCpu.h & JCellDivCpu.cpp
Declares/implements the class responsible of generating the Neighbour List in CPU.

### JCellDivCpuSingle.h & JCellDivCpuSingle.cpp
Declares/implements the class responsible of generating the Neighbour List in Single-CPU.

### JSphCpu.h & JSphCpu.cpp
Declares/implements the class that defines the attributes and functions used only in CPU simulations.

### JSphCpuSingle.h & JSphCpuSingle.cpp
Declares/implements the class that defines the attributes and functions used only in Single-CPU.

### JSphTimersCpu.h
Measures time intervals during CPU execution.

## SPH SOLVER ONLY FOR GPU EXECUTIONS

### JArraysGpu.h & JArraysGpu.cpp
Declares/implements the class that manages arrays with memory allocated in GPU.

### JBlockSizeAuto.h & JBlockSizeAuto.cpp
Declares/implements the class that manages the automatic computation of optimum Blocksize.

### JCellDivGpu.h & JCellDivGpu.cpp
Declares/implements the class responsible of generating the Neighbour List (NL) in GPU.

### JCellDivGpu_ker.h & JCellDivGpu_ker.cu
Declares/implements functions and CUDA kernels to generate the NL in GPU.

### JCellDivGpuSingle.h & JCellDivGpuSingle.cpp
Declares/implements the class that defines the class responsible of generating the NL in Single-GPU.

### JCellDivGpuSingle_ker.h & JCellDivGpuSingle_ker.cu
Declares/implements functions and CUDA kernels to compute operations of the NL.

### JGauge_ker.h & JGauge_ker.cu
Declares/implements functions and CUDA kernels for classes that manage gauges.

### JSphGpu.h & JSphGpu.cpp
Declares/implements the class that defines the attributes and functions used only in GPU simulations.

### JSphGpu_ker.h & JSphGpu_ker.cu
Declares/implements functions and CUDA kernels for the Particle Interaction and System Update.

### JSphGpuSingle.h & JSphGpuSingle.cpp
Declares/implements the class that defines the attributes and functions used only in single-GPU.

### JSphTimersGpu.h
Measures time intervals during GPU execution.

## 6.3.3 CPU Source files
The source file **JSphCpuSingle.cpp** can be better understood with the help of the diagram of calls represented in Figure 6-1. Note that particle interactions are not performed in terms of cells. In the current version each CPU thread computes all neighbour interactions of a set of particles that can belong to the same cell or not. The cell division of the domain is only used to look for neighbours in an efficient way.

<p align="center">
<img src="https://i.imgur.com/o7t9E1h.png"/>
</p>
<p align="center">
<img src="https://i.imgur.com/TS63t6H.png"/>
</p>

<p align="center">
<strong>Figure 6-1.</strong> Workflow of <strong>JSphCpuSingle.cpp</strong> (v4.0) when using Verlet time algorithm.
</p>

When the Symplectic time integration scheme is used the step is split in predictor and corrector steps. Thus, Figure 6-2 shows the workflow and calls of the CPU code using this time scheme:

<p align="center">
<img src="https://i.imgur.com/anNNKsn.jpg"/>
</p>
<p align="center">
<img src="https://i.imgur.com/AvpEFkq.png"/>
</p>

<p align="center">
<strong>Figure 6-2.</strong> Workflow of JSphCpuSingle.cpp (v4.0) when using Symplectic time algorithm.
</p>

Note that _JSphCpu::Interaction_Forces_ performs the particle interaction in CPU using the template _InteractionForcesT_. Thus, the interaction between particles is carried out considering different parameters and considering the type of particles involved in the interaction as it can be seen in Figure 6-3 and Table 6-2:

<p align="center">
<img src="https://i.imgur.com/CwUqQWU.png" width="400px" />
</p>

<p align="center">
<strong>Figure 6-3.</strong> Call graph for the template InteractionForcesT (v4.0).
</p>

<p align="center">
<strong>Table 6-2.</strong> Different particle interactions can be performed depending on the type of particles.
</p>

<p align="center">
<img src="https://i.imgur.com/a3hSy5u.png"/>
</p>

## 6.3.4 GPU source files

The source file **JSphGpuSingle.cpp** can be better understood with the workflow represented in Figure 6-4 that includes the functions implemented in the GPU files. The dashed boxes indicate the CUDA kernels implemented in the CUDA files (_JSphGpu_ker.cu_).

<p align="center">
<img src="https://i.imgur.com/13pZSp5.jpg"/>
</p>
<p align="center">
<img src="https://i.imgur.com/A8XR8WV.png"/>
</p>
<p align="center">
<img src="https://i.imgur.com/nqhtVzt.png"/>
</p>

<p align="center">
<strong>Figure 6-4.</strong> Workflow of <strong>JSphGpuSingle.cpp</strong> (v4.0) when using Verlet time algorithm.
</p>

## 6.4 Compiling on Windows using VS

In **DualSPHysics_v5.0/src** there are also several folders:
* source: contains all the source files;
* lib/vs2013 & lib/vs2015: precompiled libraries for x64 (debug and release);
* VS: includes the project file _DualSPHysics4Re_vs2015.sln_ is provided to be opened with Visual Studio Community 2015.

Different configurations can be chosen for compilation:
a) Release: for CPU and GPU 
b) ReleaseCPU: only for CPU 

The result of the compilation is the executable _DualSPHysics5.0_win64.exe_ or _DualSPHysics5.0CPU_win64.exe_ created in **DualSPHysics_v5.0/bin/windows**. The GPU codes were compiled for compute capabilities sm30, sm35, sm50, sm52 sm61, sm70 and with CUDA v9.2.

The Visual Studio project is created including the libraries for OpenMP in the executable. To not include them, user can modify _Props config -> C/C++ -> Language -> OpenMp_ and compile again. The use of OpenMP can be also deactivated by commenting the code line `#define OMP_USE` in **OmpDefs.h. **
 
In order to simulate more than 2000 and up to 65000 floating or solid objects, the user should activate or comment the code line `#define CODE_SIZE4` in **Types.h**.


## 6.5 Compiling on Linux

As mentioned before, in **DualSPHysics_v5.0/src** there are also several folders:
* source: contains all the source files and makefiles;
* lib/linux_gcc: precompiled libraries for GCC;

Makefiles can be used to compile the code in linux:
* make –f **Makefile**: full compilation just using make command
* make –f **Makefile_cpu**: only for CPU
  
The result of the compilation is the executable _DualSPHysics5.0_linux64_ or _DualSPHysics5.0CPU_linux64_ created in ****DualSPHysics_v4.4/bin/linux****.

To exclude the use of OpenMP you have to remove the flags `–fopenmp` and `-lgomp` in the Makefile and comment line `#define OMP_USE` in **OmpDefs.h**.
In order to simulate more than 2000 and up to 65000 floating or solid objects, the user should activate or comment the code line `#define CODE_SIZE4` in **Types.h**.

You can see the content of the makefile [here](https://github.com/DualSPHysics/DualSPHysics/blob/master/src/source/Makefile)

The user can modify the compilation options, the path of the CUDA toolkit directory, the GPU architecture. The GPU code is already compiled (bin) for compute capabilities sm30, sm35, sm50, sm52 sm61, sm70 and with CUDA v9.2.

Note that if you are using a GCC version greater than v4.9 you should set the `"USE_GCC5"` option to `"YES"` to avoid compatibility issues during the compilation.


## 6.6 Compiling using CMAKE

A new building method is supported since the version 4.0 of DualSPHysics using CMAKE ([https://cmake.org/](https://cmake.org/)). CMAKE is a cross-platform and an independent building system for compilation. This software generates native building files (like makefiles or Visual Studio projects) for any platform. The location of dependencies and the needed flags are automatically determined.

**Compile instructions for Microsoft Windows with Cmake**:
The building system needs the following dependencies:
* Cmake version 2.8.10 or greater ([https://cmake.org/download/](https://cmake.org/download/))
* Nvidia CUDA Toolkit version 4.0 or higher.
* Visual Studio 2013 or 2015 version.
* File “CMakeLists.txt” in **src/source**.

<p align="center">
<img src="https://imgur.com/OV4xYO1.png" width="650px" />
</p>

The folder **build** will be created in **src/source**. This folder will contain the building files so it can be safely removed in case of rebuilding, it can actually be placed anywhere where the user has writing permissions.
Afterwards, open the Cmake application, a new window will appear:

Paste the **Source** folder path in the textbox labelled as **Where is the source code**, and paste the build folder path into the **Where to build the binaries** textbox. Once the paths are introduced, the **Configure** button should be pressed. A new dialog will appear asking for the compiler to be used in the project. Please, remember that only Visual Studio 2013 and Visual Studio 2015 for 64 bit are supported.

If the configuration succeeds, now press the **Generate** button. This will generate a Visual Studio project file into the **build** directory. 
In order to compile both CPU and GPU versions, just change configuration to **Release** and compile. If the user only wants to compile one version, one can choose one of the solutions **DualSPHysics4.4CPU** or **DualSPHysics4.4** for CPU or GPU versions respectively, and compile it.

The user can freely customize the **src/source/CMakeLists.txt** file to add new source files or any other modifications. For more information about how to edit this file, please, refer to official Cmake documentation ([https://cmake.org/documentation/](https://cmake.org/documentation/)).

**Compile instructions for Linux with Cmake**

The building system needs the following dependencies:
* Cmake version 2.8.10 or higher.
* Nvidia CUDA Toolkit version 4.0 or higher.
* GNU G++ compiler 4.4 version or higher.
* File “CMakeLists.txt” in **src/source**.

The folder **build** will be created in **src/source**. This folder will contain the building files so it can be safely removed in case of rebuilding; it can actually be placed anywhere where the user has writing permissions. To create this folder and run Cmake just type the commands in bold shown below:

```
> cd src/source
> mkdir build
> cd build
> cmake ..
-- The C compiler identification is GNU 6.4.1
-- The CXX compiler identification is GNU 6.4.1
-- Check for working C compiler: /usr/bin/gcc-6
-- Check for working C compiler: /usr/bin/gcc-6 -- works
-- Detecting C compiler ABI info
-- Detecting C compiler ABI info - done
-- Detecting C compile features
-- Detecting C compile features - done
-- Check for working CXX compiler: /usr/bin/g++-6
-- Check for working CXX compiler: /usr/bin/g++-6 -- works
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Detecting CXX compile features
-- Detecting CXX compile features - done
-- Looking for pthread.h
-- Looking for pthread.h - found
-- Looking for pthread_create
-- Looking for pthread_create - not found
-- Looking for pthread_create in pthreads
-- Looking for pthread_create in pthreads - not found
-- Looking for pthread_create in pthread
-- Looking for pthread_create in pthread - found
-- Found Threads: TRUE  
Using cuda version >=9.1
Using libraries for gcc
-- Found OpenMP_C: -fopenmp (found version "4.5") 
-- Found OpenMP_CXX: -fopenmp (found version "4.5") 
-- Found OpenMP: TRUE (found version "4.5")  
-- Configuring done
-- Generating done
-- Build files have been written to: /home/user/DualSPHysics/src/source/build
```

The command **cmake ..** will search for a Cmake file (**CMakeLists.txt**) in the specified folder. As mentioned before, the user can freely customize this file to add new source files or any other modifications. For more information about how to edit this file, please, refer to Cmake official documentation ([https://cmake.org/documentation/](https://cmake.org/documentation/)).

Once the cmake command runs without error, a Makefile can be found in the **build** folder. To build both CPU and GPU versions of DualSPHysics just type **make**. If the user only needs to build one of the executable files he can use the commands **make DualSPHysics4.4CPU** or **make DualSPHysics4.4** for CPU and GPU versions respectively.
In order to install the compiled binaries into the **bin** folder, the user can either copy the executable files or type the command **make install**.
